\label[chapter_1]
\chap Introduction
Despite the amount of effort put in AI research to develop a program capable of playing real-time strategy (RTS) video games and recent successes of programs such as AlphaGo~\cite[Silver2016-1-27] and DeepStack~\cite[pBRGN4Ye3U2TB601], professional players in complex RTS games remain unchallenged by an expert level AIs. Making the game more fun to play for humans by developing advanced AI is not the only one benefit of AI research in this area. Tasks carried out in hardly predictable environments of those games, resemble real-world military scenario which demands to solve many complex issues quickly and satisfactory. Most of the decision making in real-world has similar nature. Therefore one can expect that techniques used in AI able to master an RTS game could perform well in other domains.
\sec Motivation
There are many challenges to overcome by AI researchers to be able for their bots to match human expertise in RTS games. In our work we would like to contribute to following ones:
\begitems 
* {\bf Adaptive planning}:
most bots are not able to adapt their strategy to counter the opponent. Instead, they use some hard-coded triggers to select between sets of strategies or mix between them based on performance or by random. 
* {\bf Domain Knowledge integration}:
this is related to lack of ability to adapt as many bots creators struggle to incorporate various forms of domain knowledge to their bots. Excellent sources of domain knowledge for the game are demonstrations of human play. Observing other players is a natural way for a human to learn to play the game but it does not hold for bots.
* {\bf Domain Knowledge integration}:
playing RTS is multi-scale AI problem. Bots creators know that and decompose the problem to sub-problem. However, approach how they do that varies from bot to bot.
\enditems
The test-bench for our research is RTS game Starcraft:~Brood War where all three challenges and the ones described in~\ref[challenges] remain valid. Researchers have been working on techniques to solve the issues of bots in many RTS games over a decade. However, StarCraft:~Brood War has become the first choice for this kind of research in recent years. It has one significant advantage over other similar games in a number of competitions for AI StarCraft bots (organized by AIIDE, CIG, and SSCAIT~\cite[Churchill2016-6-6]) so one can easily see how created bot is doing against others. Another advantage is that playersâ€™ community around the game is still active even though the game was released back in 1998.
\sec Objectives
Our primary goal of this work is to develop a bot for StarCraft:~Brood War which learns its decision-making processes from the demonstration. To meet this aim we set up following guideline:
\begitems 
\style n
* Review current approaches for building expert level real time strategy game-playing AI. 
* Identify decision-making processes realized by a human player in the expert level gameplay of real-time strategy game StarCraft:~Brood War.
* Implement game-playing agent for StarCraft Brood War. To reduce complexity and amount of required expert knowledge, design the game-playing AI as a highly decentralized multiagent system with the ability to learn from demonstration (watching replays of StarCraft:~Brood War games played by humans).
* Use Markov decision processes and Inverse Reinforcement Learning to train decision modules for individual MAS agents.
* Evaluate and discuss the capabilities of game-playing AI and compare it to state of the art AIs.
\enditems
\sec Contribution
By meeting our objectives, we deliver following contributions:
\begitems 
* By learning decision-making in a different situation of the game by observing experts, we eliminate most of the hard-coded behavior in our bot in the sake of better adaptability. It is also a good example how to encode part of the domain knowledge which is otherwise hard to get on the highest level of abstraction.
* Using Markov decision processes and Inverse Reinforcement Learning is way how to explain/decide behavior in given situation. Approaching problem trough utility based planning has some advantages over goal-oriented planning used in most current bots (more on differences in~\ref[agent_types]).
* Decomposition of the problem is inevitable as hardly only one technique can be used to solve all subproblems (which is in alignment with results of famous No Free Lunch Theorems%
\fnote{\url{http://www.no-free-lunch.org}}), we developed a prototype of unified architecture in the form of an opinionated framework based on the multi-agent system. Not only our StarCraft bot project can benefit from this as our framework is domain independent.
\enditems
\sec Outline
In~\ref[chapter_2] we give a broader introduction to the domain of RTS games, StarCraft and analyze decision making involved to identify decision-making processes. \ref[chapter_3] is a continuation of~\ref[chapter_2] and presents challenges and techniques in RTS game AI development. Another purpose of that chapter is to introduce ways how bots are being developed. All of this is useful in our attempt to build our bot. In~\ref[chapter_4] we provide a description of Inverse Reinforcement Learning technique which we use to learn to make decisions in the same way as humans do it in given situation. \ref[chapter_5] presents an explanation of what we understand under term agent as we see our bot as an agent. An important part of this chapter is to explain types of the agents to give some classification of them as our bot is partially concerning utility in contrast to common bots. We also provide a description of the multi-agent system as we use it for task decomposition in the form of the opinionated framework described in~\ref[chapter_6]. \ref[chapter_6] is also a place where we bring everything together as we present way how we integrated decision making to our bot and how other techniques can be incorporated. In~\ref[chapter_7] we present our initial version of the bot with examples of the framework usage and IRL integration. This chapter also evaluates its current performance and gives an analysis of current issues. In last~\ref[chapter_8], we give a recapitulation of our work and discuss directions for future work.